{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WECeh57QhL9O"
   },
   "source": [
    "---\n",
    "<h1 style=\"text-align: center;\">IF867 - Introdução à Aprendizagem Profunda</h1>\n",
    "<h2 style=\"text-align: center;\">1ª atividade prática</h2>\n",
    "\n",
    "---\n",
    "---\n",
    "*Discente:*\n",
    "\n",
    "* Gabriel D'assumpção de Carvalho - gdc2@cin.ufpe.br\n",
    "\n",
    "*Curso:*\n",
    "\n",
    "* Ciências Atuariais - 7º Período\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "29/11/2024\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRkbCshWhfya"
   },
   "source": [
    "# Instruções e Requisitos\n",
    "- Objetivo: Implementar e treinar um Multilayer Perceptron (MLP), inteiramente em [NumPy](https://numpy.org/doc/stable/) ou [Numba](https://numba.readthedocs.io/en/stable/index.html), sem o uso de bibliotecas de aprendizado profundo.\n",
    "- A atividade pode ser feita em dupla.\n",
    "\n",
    "## Tarefas\n",
    "\n",
    "__Implementação (50%):__\n",
    "\n",
    "- Construa um MLP com uma camada de entrada, pelo menos duas camadas ocultas e uma camada de saída.\n",
    "- Implemente pelo menos duas funções de ativação diferentes para as camadas ocultas; use Sigmoid e Linear para a camada de saída.\n",
    "- Implemente forward e backpropagation.\n",
    "- Implemente um otimizador de sua escolha, adequado ao problema abordado.\n",
    "- Implemente as funções de treinamento e avaliação.\n",
    "\n",
    "__Aplicação (30%):__\n",
    "\n",
    "  Teste se os seus modelos estão funcionando bem com as seguintes tarefas:\n",
    "  - Regressão\n",
    "  - Classificação binária\n",
    "\n",
    "__Experimentação (20%):__\n",
    "\n",
    "  Teste os seus modelos com variações na arquitetura, no pré-processamento, etc. Escolha pelo menos uma das seguintes opções:\n",
    "  - Variações na inicialização de pesos\n",
    "  - Variações na arquitetura\n",
    "  - Implementação de técnicas de regularização\n",
    "  - Visualização das ativações e gradientes\n",
    "\n",
    "***Bônus:*** Implemente o MLP utilizando uma biblioteca de machine learning (ex.: [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/?hl=pt-br), [tinygrad](https://docs.tinygrad.org/), [Jax](https://jax.readthedocs.io/en/latest/quickstart.html)) e teste-o em uma das aplicações e em um dos experimentos propostos. O bônus pode substituir um dos desafios de aplicação ou experimentos feitos em NumPy, ou simplesmente somar pontos para a pontuação geral.\n",
    "\n",
    "## Datasets recomendados:\n",
    "Aqui estão alguns datasets recomendados, mas fica a cargo do aluno escolher os datasets que utilizará na atividade, podendo escolher um dataset não listado abaixo.\n",
    "- Classificação\n",
    "\n",
    "  - [Iris](https://archive.ics.uci.edu/dataset/53/iris)\n",
    "  - [Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n",
    "  - [CDC Diabetes Health Indicators](https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators)\n",
    "\n",
    "- Regressão\n",
    "\n",
    "  - [Air Quality](https://archive.ics.uci.edu/dataset/360/air+quality)\n",
    "  - [Student Performance](https://archive.ics.uci.edu/dataset/320/student+performance)\n",
    "  - [Wine Quality](https://archive.ics.uci.edu/dataset/186/wine+quality)\n",
    "\n",
    "## Requisitos para Entrega\n",
    "\n",
    "Um notebook Jupyter (de preferência, o link do colab) ou script Python contendo:\n",
    "\n",
    "- Código: Implementação completa da MLP.\n",
    "- Gráficos e Análises: Gráficos da curva de perda, ativações, gradientes e insights do treinamento, resultantes dos experimentos com parada antecipada e diferentes técnicas de regularização.\n",
    "- Relatório: Um breve relatório detalhando o impacto de várias configurações de hiperparâmetros(ex.: inicialização de pesos, número de camadas ocultas e neurônios) e métodos de regularização no desempenho do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Data manipulation\n",
    "import pandas as pd  # Data manipulation\n",
    "import matplotlib.pyplot as plt # Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  color  \n",
       "0      8.8        6      1  \n",
       "1      9.5        6      1  \n",
       "2     10.1        6      1  \n",
       "3      9.9        6      1  \n",
       "4      9.9        6      1  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Urls of the datasets\n",
    "url_red = \"https://raw.githubusercontent.com/gabrieldadcarvalho/deep_learning/refs/heads/master/exercise_list/01/data/wine/winequality-white.csv\"\n",
    "url_white = \"https://raw.githubusercontent.com/gabrieldadcarvalho/deep_learning/refs/heads/master/exercise_list/01/data/wine/winequality-white.csv\"\n",
    "\n",
    "# Read of the arquives CSV\n",
    "red = pd.read_csv(url_red, sep=\";\")\n",
    "white = pd.read_csv(url_white, sep=\";\")\n",
    "\n",
    "# Adding a column with the color of the wine\n",
    "red[\"color\"] = 1\n",
    "white[\"color\"] = 0\n",
    "\n",
    "# Concatenation of the datasets\n",
    "wine = pd.concat([red, white], axis=0)\n",
    "\n",
    "# Print of the shape of the dataset\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Url of the iris dataset\n",
    "url_iris = \"https://raw.githubusercontent.com/gabrieldadcarvalho/deep_learning/refs/heads/master/exercise_list/01/data/iris/iris.data\"\n",
    "\n",
    "# Read of the arquives CSV\n",
    "iris = pd.read_csv(url_iris, sep=\",\", header=None)\n",
    "\n",
    "# Adding name of the variables\n",
    "iris.columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
    "\n",
    "# 5 first rows\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa sessão vai ser elaborado funções para fazer um breve tratamento no banco de dados para facilitar o aprendizado da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print statistics\n",
    "def print_stats(df, action, missing=False):\n",
    "    if missing:\n",
    "        print(f\"Variables with missing values: \\n{df.isna().sum()}\")\n",
    "        print(\"==\" * 20)\n",
    "        print(f\"Total of missing values: \\n{df.isna().sum().sum()}\")\n",
    "        print(\"==\" * 20)\n",
    "        if df.isna().any().any():\n",
    "            print(f\"Observations of missing values: \\n{df[df.isna().any(axis=1)]}\")\n",
    "            print(\"==\" * 20)\n",
    "    else:\n",
    "        print(f\"Variables with duplicated values: \\n{df.duplicated().sum()}\")\n",
    "        print(\"==\" * 20)\n",
    "        print(f\"Total of duplicated values: \\n{df.duplicated().sum()}\")\n",
    "        print(\"==\" * 20)\n",
    "        if df.duplicated().any():\n",
    "            print(\n",
    "                f\"Observations of duplicated values: \\n{df[df.duplicated(keep=False)]}\"\n",
    "            )\n",
    "            print(\"==\" * 20)\n",
    "\n",
    "    print(f\"Old shape: {df.shape}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function for removing missing values\n",
    "def drop_nan(df):\n",
    "    # Show statistics\n",
    "    print_stats(df, action=\"dropna\", missing=True)\n",
    "\n",
    "    # Drop of missing values\n",
    "    df_cleaned = df.dropna()\n",
    "    print(f\"New shape: {df_cleaned.shape}\")\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "# Function for removing duplicated values\n",
    "def drop_duplicates(df):\n",
    "    # Show Statistics\n",
    "    print_stats(df, action=\"drop_duplicates\", missing=False)\n",
    "\n",
    "    # Drop of duplicated values\n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    print(f\"New shape: {df_cleaned.shape}\")\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def trans_categorical(df):\n",
    "    print(df.info())\n",
    "    print(\"==\" * 20)\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "    if len(categorical_cols) > 0:\n",
    "        for column in categorical_cols:\n",
    "            category_dict = {\n",
    "                category: index\n",
    "                for index, category in enumerate(pd.Categorical(df[column]).categories)\n",
    "            }\n",
    "            df[column] = df[column].map(category_dict)\n",
    "        print(f\"Column: {column} has {df[column].nunique()} categories\")\n",
    "        print(\"==\" * 20)\n",
    "        print(\"Transformation was made successfully!\")\n",
    "        print(category_dict)\n",
    "        print(\"==\" * 20)\n",
    "        print(\"New info:\")\n",
    "        print(df.info())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9796 entries, 0 to 4897\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         9796 non-null   float64\n",
      " 1   volatile acidity      9796 non-null   float64\n",
      " 2   citric acid           9796 non-null   float64\n",
      " 3   residual sugar        9796 non-null   float64\n",
      " 4   chlorides             9796 non-null   float64\n",
      " 5   free sulfur dioxide   9796 non-null   float64\n",
      " 6   total sulfur dioxide  9796 non-null   float64\n",
      " 7   density               9796 non-null   float64\n",
      " 8   pH                    9796 non-null   float64\n",
      " 9   sulphates             9796 non-null   float64\n",
      " 10  alcohol               9796 non-null   float64\n",
      " 11  quality               9796 non-null   int64  \n",
      " 12  color                 9796 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 1.0 MB\n",
      "None\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "wine = trans_categorical(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables with duplicated values: \n",
      "1874\n",
      "========================================\n",
      "Total of duplicated values: \n",
      "1874\n",
      "========================================\n",
      "Observations of duplicated values: \n",
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0               7.0              0.27         0.36            20.7      0.045   \n",
      "1               6.3              0.30         0.34             1.6      0.049   \n",
      "2               8.1              0.28         0.40             6.9      0.050   \n",
      "3               7.2              0.23         0.32             8.5      0.058   \n",
      "4               7.2              0.23         0.32             8.5      0.058   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "4851            6.4              0.33         0.44             8.9      0.055   \n",
      "4855            7.1              0.23         0.39            13.7      0.058   \n",
      "4856            7.1              0.23         0.39            13.7      0.058   \n",
      "4879            6.6              0.34         0.40             8.1      0.046   \n",
      "4880            6.6              0.34         0.40             8.1      0.046   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
      "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
      "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
      "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
      "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "4851                 52.0                 164.0  0.99488  3.10       0.48   \n",
      "4855                 26.0                 172.0  0.99755  2.90       0.46   \n",
      "4856                 26.0                 172.0  0.99755  2.90       0.46   \n",
      "4879                 68.0                 170.0  0.99494  3.15       0.50   \n",
      "4880                 68.0                 170.0  0.99494  3.15       0.50   \n",
      "\n",
      "        alcohol  quality  color  \n",
      "0      8.800000        6      1  \n",
      "1      9.500000        6      1  \n",
      "2     10.100000        6      1  \n",
      "3      9.900000        6      1  \n",
      "4      9.900000        6      1  \n",
      "...         ...      ...    ...  \n",
      "4851   9.600000        5      0  \n",
      "4855   9.000000        6      0  \n",
      "4856   9.000000        6      0  \n",
      "4879   9.533333        6      0  \n",
      "4880   9.533333        6      0  \n",
      "\n",
      "[3418 rows x 13 columns]\n",
      "========================================\n",
      "Old shape: (9796, 13)\n",
      "New shape: (7922, 13)\n"
     ]
    }
   ],
   "source": [
    "wine = drop_duplicates(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables with missing values: \n",
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "color                   0\n",
      "dtype: int64\n",
      "========================================\n",
      "Total of missing values: \n",
      "0\n",
      "========================================\n",
      "Old shape: (7922, 13)\n",
      "New shape: (7922, 13)\n"
     ]
    }
   ],
   "source": [
    "wine = drop_nan(wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme observado nas funções anteriores, o dataframe do banco de dados de vinho não apresenta dados ausentes em nenhuma de suas variáveis. No entanto, foram identificados 1874 dados duplicados, sendo metade referente a vinhos de cor vermelha e a outra metade a vinhos de cor branca. Esse cenário ocorre devido ao banco de dados conter inicialmente 9796 registros, e após a remoção das duplicatas, o número de observações foi reduzido para 7922. Considerando esse ajuste, o impacto da remoção das duplicatas pode não ser tão significativo, uma vez que a base de dados continua representando uma quantidade substancial de informações.\n",
    "\n",
    "Vale ressaltar que o objetivo desta atividade é desenvolver um algoritmo de MPL (Multilayer Perceptron) sem o uso de bibliotecas específicas de machine learning. Portanto, não nos aprofundamos em uma análise exploratória mais robusta. Não foi realizada uma investigação detalhada para avaliar o impacto das duplicatas na distribuição das variáveis ou para investigar se essas duplicações podem ser atribuídas a erros de arredondamento. Isso é especialmente relevante, pois das 12 variáveis independentes do conjunto de dados, 11 são contínuas, o que pode justificar variações numéricas pequenas que, eventualmente, resultam em duplicações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "========================================\n",
      "Column: species has 3 categories\n",
      "========================================\n",
      "Transformation was made successfully!\n",
      "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
      "========================================\n",
      "New info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 6.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "iris = trans_categorical(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables with missing values: \n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n",
      "========================================\n",
      "Total of missing values: \n",
      "0\n",
      "========================================\n",
      "Old shape: (150, 5)\n",
      "New shape: (150, 5)\n"
     ]
    }
   ],
   "source": [
    "iris = drop_nan(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables with duplicated values: \n",
      "3\n",
      "========================================\n",
      "Total of duplicated values: \n",
      "3\n",
      "========================================\n",
      "Observations of duplicated values: \n",
      "     sepal_length  sepal_width  petal_length  petal_width  species\n",
      "9             4.9          3.1           1.5          0.1        0\n",
      "34            4.9          3.1           1.5          0.1        0\n",
      "37            4.9          3.1           1.5          0.1        0\n",
      "101           5.8          2.7           5.1          1.9        2\n",
      "142           5.8          2.7           5.1          1.9        2\n",
      "========================================\n",
      "Old shape: (150, 5)\n",
      "New shape: (147, 5)\n"
     ]
    }
   ],
   "source": [
    "iris = drop_duplicates(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No banco de dados Iris, nenhum dado ausente foi identificado nas variáveis. Foi realizada a remoção de 3 observações duplicadas, resultando em uma redução do número total de observações de 150 para 147. Essa remoção representou uma perda de apenas 2% da base de dados, o que pode ser considerado um impacto mínimo na integridade do conjunto de dados."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WECeh57QhL9O"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
